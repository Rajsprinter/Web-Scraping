{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442aefab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2634300612.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    import requests for BeautifulSoup from bs4 and pandas as pd\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests for BeautifulSoup from bs4 and pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "The function get_imdb_top_indian_movies(url):\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    films = []\n",
    "\n",
    "\n",
    "\n",
    "    # Locate every movie container\n",
    "\n",
    "    soup.find_all('div', class_='lister-item-content') containers\n",
    "\n",
    "\n",
    "\n",
    "    # Top 100 films for container in containers[:100]\n",
    "\n",
    "        container.find('a').text title =\n",
    "\n",
    "        year is equal to container.find('span', class_='lister-item-year')..text.strip('()')\n",
    "\n",
    "        rating is equal to container.find('span', class_='ipl-rating-star__rating').text\n",
    "\n",
    "        movies.append('Year': year, 'Rating': rating, 'Name': title)\n",
    "\n",
    "\n",
    "\n",
    "    # Make a DataFrame\n",
    "\n",
    "    movie = df.DataFrame(pd).\n",
    "\n",
    "    print(df)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "\n",
    "get_imdb_highest_indian_filmsThe link is \"https://www.imdb.com/list/ls056092300/.\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6aec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests for import from bs4 into BeautifulSoup\n",
    "\n",
    "\n",
    "get_patreon_post_details(url) def\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    postings are same to []\n",
    "\n",
    "\n",
    "\n",
    "    In soup.find_all('div', class_='sc-jTzLTM'), for post:\n",
    "\n",
    "        title = post.find('h2').if post.find('h2') else text \"N/A\"\n",
    "\n",
    "        post.find('time')['datetime'] = date 'N/A' if post.find('time') else\n",
    "\n",
    "        class_='content', content = post.find('div').If post.find('div', class_='content'), text.strip() else \"N/A\"\n",
    "\n",
    "        Likes are returned via post.find('div', class_='likeCount').If post.find('div', class_='likeCount'), then text.strip() otherwise \"0\"\n",
    "\n",
    "        If post.find('a', href=True) and 'youtube' are present in post.find('a', href=True)['href'], then youtube_link = post.find('a', href=True)['href'] else \"N/A\"\n",
    "\n",
    "\n",
    "\n",
    "        posts.append({'Likes': likes, 'Content': content, 'Date': date, 'Heading': heading, 'YouTube Link': youtube_link})\n",
    "\n",
    "\n",
    "\n",
    "    print (posts)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "\n",
    "get_post_details_from_patreon('https://www.patreon.com/coreyms')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests for import from bs4 into BeautifulSoup\n",
    "\n",
    "\n",
    "find_house_details(locality) def:\n",
    "\n",
    "    url = f\"https://www.nobroker.in/property/sale/{locality.replace(' ', '-')}_bangalore\"\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    dwellings = []\n",
    "\n",
    "\n",
    "\n",
    "    for the home in soup.find_all(class_='card', div):\n",
    "\n",
    "        title is equivalent to house.find('span', class_='house-title').text.strip() if class_='house-title', house.find('span'), otherwise 'N/A'\n",
    "\n",
    "        house.find('div', class_='location') gives location.If house.find('div', class_='location'), then text.strip() else \"N/A\"\n",
    "\n",
    "        house.find('span', class_='size'), area = house.If house.find('span', class_='size'), then text.strip(); otherwise, 'N/A'\n",
    "\n",
    "        house.find('div', class_='emi') yields emi.if house.find('div', class_='emi') then text.strip() else 'N/A'\n",
    "\n",
    "        price is equal to house.find('div', class_='price').text.strip() if class_='price', house.find('div') else 'N/A'\n",
    "\n",
    "\n",
    "\n",
    "        houses.append({'Location': location, 'Area': area, 'EMI': emi, 'Price': price})\n",
    "\n",
    "\n",
    "\n",
    "    print (homes)\n",
    "\n",
    "\n",
    "\n",
    "# Usage examples in three locations\n",
    "\n",
    "locals = ['Jayanagar, Rajaji Nagar, and Indira Nagar']\n",
    "\n",
    "regarding loc in localities:\n",
    "\n",
    "    obtain_home_details(loc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests for import from bs4 into BeautifulSoup\n",
    "\n",
    "\n",
    "get_bewakoof_products(url) def:\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    goods = []\n",
    "\n",
    "\n",
    "\n",
    "    soup.find_all('div', class_='productCardBox') for product[:10]: # The first ten items\n",
    "\n",
    "        name = product.text.strip().find('h3').\n",
    "\n",
    "        'span', class_='discountedPriceText', price = product.find..text.strip()\n",
    "\n",
    "        product.find('img') image_url['src']\n",
    "\n",
    "\n",
    "\n",
    "        products.append({'Image URL': image_url}, 'Price': price, 'Product Name': name)\n",
    "\n",
    "\n",
    "\n",
    "    print (items)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "\n",
    "get_bewakoof_products() returns a list of the best sellers with the sorting option set to \"popular.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests for import from bs4 into BeautifulSoup\n",
    "\n",
    "\n",
    "Get CNN BC News (link) def\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    news is equal to []\n",
    "\n",
    "\n",
    "\n",
    "    soup.find_all('div', class_='Card-titleContainer') for article:\n",
    "\n",
    "        heading = article.text.strip().find('a').\n",
    "\n",
    "        article = date.find('datetime']['time'] in the event of an article.locate('time') if not 'N/A'\n",
    "\n",
    "        article.find('a')['href'] = link\n",
    "\n",
    "\n",
    "\n",
    "        news.append({'Link': link}, 'Heading': heading, 'Date': date)\n",
    "\n",
    "\n",
    "\n",
    "    print (news)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "\n",
    "Get CNN News by entering the URL \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests for import from bs4 into BeautifulSoup\n",
    "\n",
    "\n",
    "def get_agriculture_articles_with_ai(url):\n",
    "\n",
    "    answer is equal to requests.get(url).\n",
    "\n",
    "    soup = BeautifulSoup('html.parser', response.text)\n",
    "\n",
    "    articles = []\n",
    "\n",
    "\n",
    "\n",
    "    soup.find_all('div', class_='article-item__body') for article:\n",
    "\n",
    "        article.find('a').text.strip() title\n",
    "\n",
    "        article.find('div', class_='article-item__date'), date = article.text.strip()\n",
    "\n",
    "        class_='article-item__authors', author = article.find('div').text.strip()\n",
    "\n",
    "\n",
    "\n",
    "        articles.append({'Date': date, 'Author': author}, 'Title': title})\n",
    "\n",
    "\n",
    "\n",
    "    print (pieces)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "\n",
    "retrieval of \"https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/\"); obtain AI_agriculture_articles\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
